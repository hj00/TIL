{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 전처리\n",
    "### >> 문서 분석의 경우 숫자로 구성된 특징 벡터(feature vector)를 문서로부터 추출하는 과정이 필요. -> 문서 전처리(document preprocessing) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW(Bag of Word)\n",
    "### >> 문서를 숫자 벡터로 변환하는 가장 기본적인 방법.\n",
    "### >> 문서(D1, D2, D2)를 구성하는 고정된 단어장(W1, W2, W3)을 만들고 Di라는 개별 문서에 단어장에 해당하는 단어들이 포함되어있는지를 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn의 문서 전처리 기능\n",
    "### Scikit-Learn의 feature_extraction.text 서브 패키지\n",
    "#### >> CountVectorizer : 문서 집합으로부터 단어의 수를 세어 카운트 행렬을 만든다.\n",
    "#### >> TfidVectorizer : 문서 집합으로부터 단어의 수를 세고 TF-IDF 방식으로 단어의 가중치를 조정한 카운트 행렬 생성\n",
    "#### >> HashingVectorizer : hashing trick을 사용하여 빠르게 카운트 행렬을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 0,\n",
       " 'document': 1,\n",
       " 'first': 2,\n",
       " 'is': 3,\n",
       " 'last': 4,\n",
       " 'one': 5,\n",
       " 'second': 6,\n",
       " 'the': 7,\n",
       " 'third': 8,\n",
       " 'this': 9}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?'\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 1, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['This is the second document.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 처리 옵션\n",
    "### CountVectorizer는 다양한 인수를 가진다. 그 중 중요한 것들은 다음과 같다.\n",
    "#### stop_words : 문자열 {‘english’}, 리스트 또는 None (디폴트) / stop words 목록.‘english’이면 영어용 스탑 워드 사용.\n",
    "#### analyzer : 문자열 {‘word’, ‘char’, ‘char_wb’} 또는 함수 / 단어 n-그램, 문자 n-그램, 단어 내의 문자 n-그램\n",
    "#### tokenizer : 함수 또는 None (디폴트) / 토큰 생성 함수 .\n",
    "#### token_pattern : string / 토큰 정의용 정규 표현식\n",
    "#### ngram_range : (min_n, max_n) 튜플 / n-그램 범위\n",
    "#### max_df : 정수 또는 [0.0, 1.0] 사이의 실수. 디폴트 1 / 단어장에 포함되기 위한 최대 빈도\n",
    "#### min_df : 정수 또는 [0.0, 1.0] 사이의 실수. 디폴트 1 / 단어장에 포함되기 위한 최소 빈도\n",
    "#### vocabulary : 사전이나 리스트 / 단어장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "### >> 문서에서 단어장을 생성할 떄 무시할 수 있는 단어를 의미.\n",
    "### >>> 보통 영어의 관사나 접속사. 한국어의 조사 등이 해당됨\n",
    "### >>> stop_sords 인수로 조절할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 0, 'first': 1, 'last': 2, 'one': 3, 'second': 4, 'third': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"the\", \"this\"]).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 0, 'second': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\").fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰(token)\n",
    "### >> 토큰은 문서에서 단어장을 생성할 떄 하나의 단어가 되는 단위를 말한다.\n",
    "### >>> analyzer, tokenizer, token_pattern 등의 인수로 조절 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '?': 2,\n",
       " 'a': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'l': 10,\n",
       " 'm': 11,\n",
       " 'n': 12,\n",
       " 'o': 13,\n",
       " 'r': 14,\n",
       " 's': 15,\n",
       " 't': 16,\n",
       " 'u': 17}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=\"char\").fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " '?': 1,\n",
       " 'and': 2,\n",
       " 'document': 3,\n",
       " 'first': 4,\n",
       " 'is': 5,\n",
       " 'last': 6,\n",
       " 'one': 7,\n",
       " 'second': 8,\n",
       " 'the': 9,\n",
       " 'third': 10,\n",
       " 'this': 11}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "vect = CountVectorizer(tokenizer=nltk.word_tokenize).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0, 'third': 1, 'this': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(token_pattern=\"t\\w+\").fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-그램\n",
    "### >> n=그램은 단어장 생성에 사용할 토큰의 크기를 결정.\n",
    "#### >>> 1-그림은 토큰 하나만 단어로 사용하며, 2-그램은 두 개의 연결된 토큰을 하나의 단어로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and the': 0,\n",
       " 'first document': 1,\n",
       " 'is the': 2,\n",
       " 'is this': 3,\n",
       " 'last document': 4,\n",
       " 'second document': 5,\n",
       " 'second second': 6,\n",
       " 'the first': 7,\n",
       " 'the last': 8,\n",
       " 'the second': 9,\n",
       " 'the third': 10,\n",
       " 'third one': 11,\n",
       " 'this is': 12,\n",
       " 'this the': 13}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2)).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0, 'the third': 1, 'third': 2, 'this': 3, 'this the': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), token_pattern=\"t\\w+\").fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빈도수\n",
    "### >> max_df, min_df 인수 사용. 문서에서 토큰이 나타난 횟수를 기준으로 단어장 구성 가능. \n",
    "#### >>> max_df로 지정한 값을 초과하거나 min_dif로 지정한 값보다 작은 경우에는 무시.\n",
    "#### >>> 인수 값은 정수인 경우 횟수, 부동소수점인 경우 비중 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'document': 0, 'first': 1, 'is': 2, 'this': 3},\n",
       " {'and', 'last', 'one', 'second', 'the', 'third'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_df=4, min_df=2).fit(corpus)\n",
    "vect.vocabulary_, vect.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(corpus).toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(Team Frequency - Inverse Document Frequency)\n",
    "### >> 단어를 갯수 그대로 카운트하지 않고 모든 문서에 공통적으로 들어있는 단어의 경우 문서 구별 능력이 떨어진다고 보아 가중치를 축소하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.38947624,  0.55775063,  0.4629834 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.32941651,  0.        ,  0.4629834 ],\n",
       "       [ 0.        ,  0.24151532,  0.        ,  0.28709733,  0.        ,\n",
       "         0.        ,  0.85737594,  0.20427211,  0.        ,  0.28709733],\n",
       "       [ 0.55666851,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.55666851,  0.        ,  0.26525553,  0.55666851,  0.        ],\n",
       "       [ 0.        ,  0.38947624,  0.55775063,  0.4629834 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.32941651,  0.        ,  0.4629834 ],\n",
       "       [ 0.        ,  0.45333103,  0.        ,  0.        ,  0.80465933,\n",
       "         0.        ,  0.        ,  0.38342448,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidv = TfidfVectorizer().fit(corpus)\n",
    "tfidv.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing Trick\n",
    "#### >> CountVectorizer는 모든 작업을 메모리 상에서 수행하므로 처리할 문서의 크기가 커지면 속도가 느려지거나 실행이 불가능해진다.\n",
    "#### >> HashingVectorizer를 사용하면 해시 함수를 사용하여 단어에 대한 인덱스 번호를 생성하기 때문에 메모리 및 실행 시간을 즐길 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty = fetch_20newsgroups()\n",
    "len(twenty.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time CountVectorizer().fit(twenty.data).transform(twenty.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv = HashingVectorizer(n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<11314x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 112863 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time hv.transform(twenty.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석기 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bought': 0,\n",
       " 'buying': 1,\n",
       " 'buys': 2,\n",
       " 'image': 3,\n",
       " 'imagination': 4,\n",
       " 'imagine': 5,\n",
       " 'imaging': 6}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"imaging\", \"image\", \"imagination\", \"imagine\",\" buys\", \"buying\", \"bought\"]\n",
    "vect = CountVectorizer().fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twenty = fetch_20newsgroups()\n",
    "docs = twenty.data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'write': 0,\n",
       " 'writer': 1,\n",
       " 'writers': 2,\n",
       " 'writes': 3,\n",
       " 'writing': 4,\n",
       " 'writing_': 5,\n",
       " 'written': 6}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\", token_pattern=\"wri\\w+\").fit(docs)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'write': 0, 'writer': 1, 'writing_': 2, 'written': 3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.s = SnowballStemmer('english')\n",
    "        self.t = CountVectorizer(stop_words=\"english\", token_pattern=\"wri\\w+\").build_tokenizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.s.stem(t) for t in self.t(doc)]\n",
    "\n",
    "vect = CountVectorizer(tokenizer=StemTokenizer()).fit(docs)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "import string\n",
    "from konlpy.utils import pprint\n",
    "from konlpy.tag import Hannanum\n",
    "import matplotlib.pyplot as plt\n",
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "req = urlopen(\"https://www.datascienceschool.net/download-notebook/708e711429a646818b9dcbb581e0c10a/\")\n",
    "json=json.loads(req.read())\n",
    "cell = [\"\\n\".join(c[\"source\"]) for c in json[\"cells\"] if c[\"cell_type\"] == u\"markdown\"]\n",
    "docs = [w for w in hannanum.nouns(\" \".join(cell)) if ((not w[0].isnumeric()) and (w[0] not in string.punctuation))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기에서는 하나의 문서가 하나의 단어로만 이루어져 있다. 따라서 CountVectorizer로 이 문서 집합을 처리하면 각 문서는 하나의 원소만 1이고 나머지 원소는 0인 벡터가 된다. 이 벡터의 합으로 빈도를 알아보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f7b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(docs)\n",
    "count = vect.transform(docs).toarray().sum(axis=0)\n",
    "plt.bar(range(len(count)), count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x0000000004B3BC88>\n"
     ]
    }
   ],
   "source": [
    "pprint(zip(vect.get_feature_names(), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['377ad03459bf',\n",
      "  'a181562ac4d8',\n",
      "  'a1e4ed2ac65b',\n",
      "  'container',\n",
      "  'daemon',\n",
      "  'dockeruser',\n",
      "  'id',\n",
      "  'image',\n",
      "  'mingw64',\n",
      "  'tag',\n",
      "  '가능',\n",
      "  '가동',\n",
      "  '가상',\n",
      "  '가지',\n",
      "  '개념',\n",
      "  '경우',\n",
      "  '공유',\n",
      "  '관련',\n",
      "  '관련하',\n",
      "  '길벗',\n",
      "  '나오기',\n",
      "  '내부',\n",
      "  '내용',\n",
      "  '다음',\n",
      "  '대표적',\n",
      "  '대화적',\n",
      "  '대화형',\n",
      "  '데몬',\n",
      "  '도서출판',\n",
      "  '도커',\n",
      "  '동작',\n",
      "  '때문',\n",
      "  '리눅스',\n",
      "  '마지막',\n",
      "  '마찬가지',\n",
      "  '머신',\n",
      "  '명령',\n",
      "  '명령어',\n",
      "  '명시',\n",
      "  '명시해',\n",
      "  '목록',\n",
      "  '문자',\n",
      "  '문자열',\n",
      "  '문제',\n",
      "  '문헌',\n",
      "  '버튼',\n",
      "  '복사',\n",
      "  '복수',\n",
      "  '복수개의',\n",
      "  '브라우저',\n",
      "  '사용',\n",
      "  '사용법',\n",
      "  '사용자',\n",
      "  '사용해',\n",
      "  '삭제',\n",
      "  '상태',\n",
      "  '생각',\n",
      "  '생략',\n",
      "  '생성',\n",
      "  '설명',\n",
      "  '소개',\n",
      "  '수행',\n",
      "  '시스템',\n",
      "  '시작',\n",
      "  '실행',\n",
      "  '아래',\n",
      "  '아이디',\n",
      "  '여기',\n",
      "  '연결',\n",
      "  '연습',\n",
      "  '오류',\n",
      "  '옵션',\n",
      "  '외부',\n",
      "  '요약',\n",
      "  '원본',\n",
      "  '윈도우즈',\n",
      "  '으로',\n",
      "  '의미',\n",
      "  '의존',\n",
      "  '이름',\n",
      "  '이미지',\n",
      "  '이재홍',\n",
      "  '이해',\n",
      "  '일부분',\n",
      "  '입력',\n",
      "  '자동',\n",
      "  '자체',\n",
      "  '작동',\n",
      "  '작업',\n",
      "  '재시작',\n",
      "  '저장',\n",
      "  '정지',\n",
      "  '조합',\n",
      "  '존재',\n",
      "  '주의해',\n",
      "  '중복',\n",
      "  '중지',\n",
      "  '지정',\n",
      "  '초간단',\n",
      "  '최소한',\n",
      "  '추가',\n",
      "  '출력',\n",
      "  '컨테이',\n",
      "  '컨테이너',\n",
      "  '컨테이너상',\n",
      "  '컴퓨터',\n",
      "  '콜론',\n",
      "  '태그',\n",
      "  '터미널',\n",
      "  '툴박스',\n",
      "  '특정',\n",
      "  '파일',\n",
      "  '포워딩',\n",
      "  '포트',\n",
      "  '폴더',\n",
      "  '표시',\n",
      "  '프롬프트',\n",
      "  '하나',\n",
      "  '항목',\n",
      "  '해당',\n",
      "  '핵심',\n",
      "  '호스트',\n",
      "  '호스트간',\n",
      "  '확인'],\n",
      " array([ 3,  6,  1,  1,  1,  3,  1,  1, 13,  1,  2, 14,  3,  1,  1, 14,  1,\n",
      "        1,  2,  1,  1,  1,  1,  9,  1,  1,  3,  1,  1, 40,  2,  1,  1,  1,\n",
      "        3,  1, 32,  5,  1,  2,  6,  1,  3,  1,  2,  1,  1,  1,  1,  1, 25,\n",
      "        1,  1,  1, 10,  2,  2,  1,  1,  1,  1,  3,  3,  8,  1,  1, 11,  1,\n",
      "        1,  1,  1,  6,  4,  1,  1,  1,  1,  2,  1, 11, 34,  1,  1,  1,  6,\n",
      "        1,  1,  1,  2,  2,  2,  1,  1,  4,  1,  1, 14,  2,  1,  1,  2,  4,\n",
      "        1, 72,  1,  4,  1,  1,  3,  1,  2,  1,  1,  5,  1,  1,  4,  1,  3,\n",
      "        5,  1,  5,  2,  5], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "a = vect.get_feature_names(), count\n",
    "pprint(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'377ad03459bf': 0,\n",
       " 'a181562ac4d8': 1,\n",
       " 'a1e4ed2ac65b': 2,\n",
       " 'container': 3,\n",
       " 'daemon': 4,\n",
       " 'dockeruser': 5,\n",
       " 'id': 6,\n",
       " 'image': 7,\n",
       " 'mingw64': 8,\n",
       " 'tag': 9,\n",
       " '가능': 10,\n",
       " '가동': 11,\n",
       " '가상': 12,\n",
       " '가지': 13,\n",
       " '개념': 14,\n",
       " '경우': 15,\n",
       " '공유': 16,\n",
       " '관련': 17,\n",
       " '관련하': 18,\n",
       " '길벗': 19,\n",
       " '나오기': 20,\n",
       " '내부': 21,\n",
       " '내용': 22,\n",
       " '다음': 23,\n",
       " '대표적': 24,\n",
       " '대화적': 25,\n",
       " '대화형': 26,\n",
       " '데몬': 27,\n",
       " '도서출판': 28,\n",
       " '도커': 29,\n",
       " '동작': 30,\n",
       " '때문': 31,\n",
       " '리눅스': 32,\n",
       " '마지막': 33,\n",
       " '마찬가지': 34,\n",
       " '머신': 35,\n",
       " '명령': 36,\n",
       " '명령어': 37,\n",
       " '명시': 38,\n",
       " '명시해': 39,\n",
       " '목록': 40,\n",
       " '문자': 41,\n",
       " '문자열': 42,\n",
       " '문제': 43,\n",
       " '문헌': 44,\n",
       " '버튼': 45,\n",
       " '복사': 46,\n",
       " '복수': 47,\n",
       " '복수개의': 48,\n",
       " '브라우저': 49,\n",
       " '사용': 50,\n",
       " '사용법': 51,\n",
       " '사용자': 52,\n",
       " '사용해': 53,\n",
       " '삭제': 54,\n",
       " '상태': 55,\n",
       " '생각': 56,\n",
       " '생략': 57,\n",
       " '생성': 58,\n",
       " '설명': 59,\n",
       " '소개': 60,\n",
       " '수행': 61,\n",
       " '시스템': 62,\n",
       " '시작': 63,\n",
       " '실행': 64,\n",
       " '아래': 65,\n",
       " '아이디': 66,\n",
       " '여기': 67,\n",
       " '연결': 68,\n",
       " '연습': 69,\n",
       " '오류': 70,\n",
       " '옵션': 71,\n",
       " '외부': 72,\n",
       " '요약': 73,\n",
       " '원본': 74,\n",
       " '윈도우즈': 75,\n",
       " '으로': 76,\n",
       " '의미': 77,\n",
       " '의존': 78,\n",
       " '이름': 79,\n",
       " '이미지': 80,\n",
       " '이재홍': 81,\n",
       " '이해': 82,\n",
       " '일부분': 83,\n",
       " '입력': 84,\n",
       " '자동': 85,\n",
       " '자체': 86,\n",
       " '작동': 87,\n",
       " '작업': 88,\n",
       " '재시작': 89,\n",
       " '저장': 90,\n",
       " '정지': 91,\n",
       " '조합': 92,\n",
       " '존재': 93,\n",
       " '주의해': 94,\n",
       " '중복': 95,\n",
       " '중지': 96,\n",
       " '지정': 97,\n",
       " '초간단': 98,\n",
       " '최소한': 99,\n",
       " '추가': 100,\n",
       " '출력': 101,\n",
       " '컨테이': 102,\n",
       " '컨테이너': 103,\n",
       " '컨테이너상': 104,\n",
       " '컴퓨터': 105,\n",
       " '콜론': 106,\n",
       " '태그': 107,\n",
       " '터미널': 108,\n",
       " '툴박스': 109,\n",
       " '특정': 110,\n",
       " '파일': 111,\n",
       " '포워딩': 112,\n",
       " '포트': 113,\n",
       " '폴더': 114,\n",
       " '표시': 115,\n",
       " '프롬프트': 116,\n",
       " '하나': 117,\n",
       " '항목': 118,\n",
       " '해당': 119,\n",
       " '핵심': 120,\n",
       " '호스트': 121,\n",
       " '호스트간': 122,\n",
       " '확인': 123}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
